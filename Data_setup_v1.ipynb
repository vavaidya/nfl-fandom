{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nlp = en_core_web_lg.load() #just import once or will take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>City</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>De acuerdo con información de ESPN, la #NFL es...</td>\n",
       "      <td>2019-11-22 23:45:58+00:00</td>\n",
       "      <td>#NFL</td>\n",
       "      <td>https://twitter.com/tonitoNunez/status/1198024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>Ultima oportunidad para Carson Wentz y #FlyEag...</td>\n",
       "      <td>2019-11-22 22:54:57+00:00</td>\n",
       "      <td>#FlyEaglesFly #RitualNFL #NFL #NFL100 #Seahawk...</td>\n",
       "      <td>https://twitter.com/quiquegaray/status/1198012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>#FelizViernesATodos Te compartimos la agenda d...</td>\n",
       "      <td>2019-11-22 13:06:28+00:00</td>\n",
       "      <td>#FelizViernesATodos #NFL #MultimediosDeportes ...</td>\n",
       "      <td>https://twitter.com/telediario/status/11978639...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>¡Arranca @FOXImpactoNFL! #Colts vs #WeAreTexan...</td>\n",
       "      <td>2019-11-22 00:28:06+00:00</td>\n",
       "      <td>#Colts #WeAreTexans #NFLxFOX #NFL100 #NFL</td>\n",
       "      <td>https://twitter.com/eleonbaz/status/1197673070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>#Colts vs #WeAreTexans @WinOnFireInt https://b...</td>\n",
       "      <td>2019-11-21 23:51:38+00:00</td>\n",
       "      <td>#Colts #WeAreTexans #WinOnFire #Apuestas #Apue...</td>\n",
       "      <td>https://twitter.com/eleonbaz/status/1197663894...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_count         City  \\\n",
       "0            0  Mexico City   \n",
       "1            1  Mexico City   \n",
       "2            2  Mexico City   \n",
       "3            3  Mexico City   \n",
       "4            4  Mexico City   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  De acuerdo con información de ESPN, la #NFL es...   \n",
       "1  Ultima oportunidad para Carson Wentz y #FlyEag...   \n",
       "2  #FelizViernesATodos Te compartimos la agenda d...   \n",
       "3  ¡Arranca @FOXImpactoNFL! #Colts vs #WeAreTexan...   \n",
       "4  #Colts vs #WeAreTexans @WinOnFireInt https://b...   \n",
       "\n",
       "                        date  \\\n",
       "0  2019-11-22 23:45:58+00:00   \n",
       "1  2019-11-22 22:54:57+00:00   \n",
       "2  2019-11-22 13:06:28+00:00   \n",
       "3  2019-11-22 00:28:06+00:00   \n",
       "4  2019-11-21 23:51:38+00:00   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0                                               #NFL   \n",
       "1  #FlyEaglesFly #RitualNFL #NFL #NFL100 #Seahawk...   \n",
       "2  #FelizViernesATodos #NFL #MultimediosDeportes ...   \n",
       "3          #Colts #WeAreTexans #NFLxFOX #NFL100 #NFL   \n",
       "4  #Colts #WeAreTexans #WinOnFire #Apuestas #Apue...   \n",
       "\n",
       "                                                link  \n",
       "0  https://twitter.com/tonitoNunez/status/1198024...  \n",
       "1  https://twitter.com/quiquegaray/status/1198012...  \n",
       "2  https://twitter.com/telediario/status/11978639...  \n",
       "3  https://twitter.com/eleonbaz/status/1197673070...  \n",
       "4  https://twitter.com/eleonbaz/status/1197663894...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('NFL_tweets_extra_cities.csv') #update file name\n",
    "raw.drop(['Unnamed: 0', 'got_criteria'],axis=1,inplace=True)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANSING FUNCTIONS\n",
    "\n",
    "def remove_space(s):\n",
    "    return s.replace(\"\\n\",\" \")\n",
    "\n",
    "def removepunc(item):\n",
    "    for p in punctuation:\n",
    "        item = item.lstrip().replace(p,'')\n",
    "    return item\n",
    "\n",
    "def lowerize(x):\n",
    "    return x.lower()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(s):\n",
    "    return [w for w in s if not w in stop_words] \n",
    "\n",
    "#Really not made use of this\n",
    "def lematize(l):\n",
    "    s=[]\n",
    "    for i in l:\n",
    "        s.append(wordnet_lemmatizer.lemmatize(i))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final columns of interest - tweet_words , hashtags_words\n",
    "data = raw.copy()\n",
    "\n",
    "data['tweet_clean'] = data['tweet']\n",
    "data['tweet_clean'] = data['tweet_clean'].apply(remove_space).apply(removepunc).apply(lowerize) \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "data['tweet_words'] = data['tweet_clean'].apply(word_tokenize).apply(set).apply(list).apply(remove_stopwords)\n",
    "\n",
    "\n",
    "data['hashtags_clean'] = data['hashtags']\n",
    "data['hashtags_clean'] = data['hashtags_clean'].apply(remove_space).apply(removepunc) \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "data['hashtags_words'] = data['hashtags_clean'].apply(word_tokenize).apply(set).apply(list).apply(remove_stopwords)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
